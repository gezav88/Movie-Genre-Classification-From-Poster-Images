{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"Project_F_MOVIE_GENRE_CLASS_ALG_1.ipynb","provenance":[{"file_id":"1SoxTGlumsAQ5LYLMwWGnbLe55eM1pfB2","timestamp":1576040051251}],"collapsed_sections":["9-6fK1OCFeZi","OsDbEqrZFeZw","ckoTJPWFFeaC","nc3ej6CbFeaF","9U5-o_WmFeaL","VNkmEuCbFeaV","Rc7Yc9M7Feau","UBvB5qxBFea3","VyJ1og4TFea8","wMVg7vISFebe","W8KEufJfFebn","bLV3rHioFebs","9UoOP-znFebz","xQskPlsyFeb2","eEgmIltdFecY","K-wfunCiFeca"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"I5nKTL5gFeX0","colab_type":"text"},"source":["# Project F\n","* Gerardo Zavala A.\n","* Dileep Badveli\n","*  Alex McKinnon\n","\n","---------------------------\n","* id: gzavala@ncsu.edu\n","* id: dbadvel@ncsu.edu\n","* id: ajmckin2@ncsu.edu\n","\n","\n","\n","# Movie Genre Classification "]},{"cell_type":"markdown","metadata":{"id":"_lR9ij0MFeX4","colab_type":"text"},"source":["## Motivation:"]},{"cell_type":"markdown","metadata":{"id":"8NWK2xa2FeX8","colab_type":"text"},"source":["Classifying a movie based only on the poster image is a difficult task to do even for humans, as sometimes poster images can be misleading of what the movie will be about. Humans can predict the movie genre based on actors and prequels if they exist, but without any prior knowledge of the movie a person would need to depend on the trailer or the movie poster. \n","\n","\n","The poster of a movie is the first interaction a person sees about a movie. The genre can be determined by the colors used, expressions on the faces, objects in the poster, etc.; these types of characteristics have been shown to affect emotions in people, and we will take advantage of that to train the network. \n","Movies can fall into more than one type of classification, so one problem to solve is building a multiclassification neural network that can categorize multiple movie genres based on the poster image.\n"]},{"cell_type":"code","metadata":{"id":"EfUsCEuFL2ZM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9RtRiaO9FeX-","colab_type":"text"},"source":["# 0. Libraries: "]},{"cell_type":"code","metadata":{"id":"VvuCYcBjOjQQ","colab_type":"code","outputId":"6776a70a-f149-44d3-da15-ea723e9f1637","executionInfo":{"status":"ok","timestamp":1576123119370,"user_tz":360,"elapsed":25743,"user":{"displayName":"Gerardo Zavala Arteaga","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCilQSBHDgPRQ9Akh0V5pOy1VIvahCjNCqpWm8Q=s64","userId":"02892556004924377229"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive',force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"E-NmBjt2m7dz","outputId":"586f860b-a25c-45e2-8179-128cdb29bca2","executionInfo":{"status":"ok","timestamp":1576123165351,"user_tz":360,"elapsed":43183,"user":{"displayName":"Gerardo Zavala Arteaga","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCilQSBHDgPRQ9Akh0V5pOy1VIvahCjNCqpWm8Q=s64","userId":"02892556004924377229"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Update keras/tensorflow for use in Google colab (needs to be done every new session)\n","!pip install --upgrade keras\n","!pip install --upgrade tensorflow\n","# Remember to press 'Restart Runtime' at end"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting keras\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n","\r\u001b[K     |▉                               | 10kB 24.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 4.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 6.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 6.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.3)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n","Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.4)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.2.5\n","    Uninstalling Keras-2.2.5:\n","      Successfully uninstalled Keras-2.2.5\n","Successfully installed keras-2.3.1\n","Collecting tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n","\u001b[K     |████████████████████████████████| 86.3MB 115kB/s \n","\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 45.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n","Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n","Collecting tensorflow-estimator<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 45.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.4)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n","Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.21.0)\n","Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (42.0.2)\n","Collecting google-auth<2,>=1.6.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/31/f944cbd5bdbcc90d5b36f0615036308c8ec1e41b4788da5b55d4900f6803/google_auth-1.8.2-py2.py3-none-any.whl (75kB)\n","\u001b[K     |████████████████████████████████| 81kB 9.1MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n","Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n","Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.11.28)\n","Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n","Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n","Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n","Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n","\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.8.2 which is incompatible.\u001b[0m\n","Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow\n","  Found existing installation: google-auth 1.4.2\n","    Uninstalling google-auth-1.4.2:\n","      Successfully uninstalled google-auth-1.4.2\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Found existing installation: tensorflow 1.15.0\n","    Uninstalling tensorflow-1.15.0:\n","      Successfully uninstalled tensorflow-1.15.0\n","Successfully installed google-auth-1.8.2 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"97uVoQXaFeYC","colab_type":"code","outputId":"dfbd5ffc-8194-42bd-bc1c-5496655ee11d","executionInfo":{"status":"ok","timestamp":1576124156987,"user_tz":300,"elapsed":1742,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Libraries for tensorflow\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","import tensorflow as tf\n","import sys\n","print(sys.version)\n","print(tf.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3.6.9 (default, Nov  7 2019, 10:44:02) \n","[GCC 8.3.0]\n","2.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GhtFquSdFeYR","colab_type":"code","colab":{}},"source":["# Common Libraries\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import os\n","\n","# Sklearn Libraries for cross validation:\n","from sklearn.model_selection import KFold\n","from keras.utils import np_utils, plot_model\n","from keras.utils.vis_utils import plot_model\n","import pathlib\n","from IPython.display import Image, display\n","import glob\n","import scipy.misc\n","from tqdm import tqdm\n","import requests  \n","import re\n","from bs4 import BeautifulSoup  \n","from urllib.request import urlretrieve\n","import ast \n","from sklearn.preprocessing import OneHotEncoder"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n8undXtSFeYV","colab_type":"text"},"source":["-----------------------------------------------------------------------------\n","# 1. Loading the Data"]},{"cell_type":"code","metadata":{"id":"8RVpGVcFnW6d","colab_type":"code","colab":{}},"source":["movie_csv='gdrive/My Drive/ECE 542 F3/data/MovieGenre.csv'\n","movies_dir='gdrive/My Drive/ECE 542 F3/data/posters/'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T6q-d1h0FeYX","colab_type":"text"},"source":["#### 1.1 Load the training files:\n","* This file contains the id (image name) and the label assigned to it. "]},{"cell_type":"code","metadata":{"id":"pzR3YLsoFeYY","colab_type":"code","colab":{}},"source":["movie_data = pd.read_csv(movie_csv, encoding=\"ISO-8859-1\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZJafwQIFeZM","colab_type":"code","outputId":"9db3bed7-1603-4860-9178-7669f8a9dfa5","executionInfo":{"status":"ok","timestamp":1576124158488,"user_tz":300,"elapsed":3191,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["movie_data.columns"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['imdbId', 'Imdb Link', 'Title', 'IMDB Score', 'Genre', 'Poster'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"rld4peAjFeZQ","colab_type":"code","colab":{}},"source":["def process_movie_data(movie_info):\n","    print(\"Initial lenght of file: \", len(movie_info))\n","    movie_info.drop_duplicates(keep='first', inplace=True)\n","    print(\"lenght after droping duplicates: \", len(movie_info))\n","    movie_info['Genre'].replace('', np.nan, inplace=True)\n","    movie_info.dropna(inplace=True)\n","    print(\"lenght after removing missing Genre: \", len(movie_info))\n","    return movie_info"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"82CaQXZ_FeZU","colab_type":"code","outputId":"a1b17194-b42e-471c-c78a-e84eb3ad6285","executionInfo":{"status":"ok","timestamp":1576124158492,"user_tz":300,"elapsed":3171,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["movie_data_process = process_movie_data(movie_data)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Initial lenght of file:  40108\n","lenght after droping duplicates:  39515\n","lenght after removing missing Genre:  38654\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MCeGCHc85_zg","colab_type":"text"},"source":["# Generate filenames to look for available posters:"]},{"cell_type":"markdown","metadata":{"id":"4K9aXyFtFeZX","colab_type":"text"},"source":["## Sample from whole data set to create a smaller to reduce computational time:"]},{"cell_type":"code","metadata":{"id":"AqJ_R9bTFeZY","colab_type":"code","outputId":"8e22cb6a-bdf3-4fe6-e2e4-799ace6626b1","executionInfo":{"status":"ok","timestamp":1576124158494,"user_tz":300,"elapsed":3144,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["movie_data_sample = movie_data_process.sample(frac=.20)\n","print(len(movie_data_sample))\n","movie_data_remaining = movie_data_process[~movie_data_process['imdbId'].isin(movie_data_sample['imdbId'])]\n","print(len(movie_data_remaining))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["7731\n","30923\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I29b4uDBFeZa","colab_type":"code","outputId":"ee654f95-979d-4c38-a659-35db2cc44820","executionInfo":{"status":"ok","timestamp":1576124158503,"user_tz":300,"elapsed":3141,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":514}},"source":["genre_df = movie_data_sample['Genre'].value_counts().reset_index()\n","genre_df.head(15)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Genre</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Drama</td>\n","      <td>781</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Comedy</td>\n","      <td>499</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Documentary</td>\n","      <td>323</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Comedy|Drama</td>\n","      <td>312</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Drama|Romance</td>\n","      <td>275</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Comedy|Drama|Romance</td>\n","      <td>233</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Comedy|Romance</td>\n","      <td>194</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Horror</td>\n","      <td>145</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Crime|Drama</td>\n","      <td>107</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Drama|Thriller</td>\n","      <td>104</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Action|Crime|Drama</td>\n","      <td>102</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Horror|Thriller</td>\n","      <td>92</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Crime|Drama|Thriller</td>\n","      <td>81</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Thriller</td>\n","      <td>65</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Crime|Drama|Mystery</td>\n","      <td>64</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   index  Genre\n","0                  Drama    781\n","1                 Comedy    499\n","2            Documentary    323\n","3           Comedy|Drama    312\n","4          Drama|Romance    275\n","5   Comedy|Drama|Romance    233\n","6         Comedy|Romance    194\n","7                 Horror    145\n","8            Crime|Drama    107\n","9         Drama|Thriller    104\n","10    Action|Crime|Drama    102\n","11       Horror|Thriller     92\n","12  Crime|Drama|Thriller     81\n","13              Thriller     65\n","14   Crime|Drama|Mystery     64"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"B97gehO2FeZd","colab_type":"code","colab":{}},"source":["genre_df.sort_values('Genre', ascending=False,inplace=True)\n","genre_top_15 = genre_df['index'][0:20].tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zIt8M0E2FeZf","colab_type":"code","outputId":"f711e918-a0c3-4a28-c231-9934db5f062b","executionInfo":{"status":"ok","timestamp":1576124158505,"user_tz":300,"elapsed":3070,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["genre_top_15"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Drama',\n"," 'Comedy',\n"," 'Documentary',\n"," 'Comedy|Drama',\n"," 'Drama|Romance',\n"," 'Comedy|Drama|Romance',\n"," 'Comedy|Romance',\n"," 'Horror',\n"," 'Crime|Drama',\n"," 'Drama|Thriller',\n"," 'Action|Crime|Drama',\n"," 'Horror|Thriller',\n"," 'Crime|Drama|Thriller',\n"," 'Thriller',\n"," 'Crime|Drama|Mystery',\n"," 'Horror|Mystery|Thriller',\n"," 'Western',\n"," 'Action|Crime|Thriller',\n"," 'Drama|War',\n"," 'Biography|Drama']"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"mL7es7aykh1x","colab_type":"text"},"source":["# Stay with top 35 Genre counts:"]},{"cell_type":"code","metadata":{"id":"eytViNqcZiOM","colab_type":"code","outputId":"c1194fed-dabb-46aa-911a-49b1fb82ccc0","executionInfo":{"status":"ok","timestamp":1576124158506,"user_tz":300,"elapsed":3052,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["movie_data_sample_2 =  movie_data_sample.loc[movie_data_sample['Genre'].isin(genre_top_15)]\n","print(len(movie_data_sample_2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3670\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MBlwoDoykHQQ","colab_type":"code","outputId":"3f29102d-78c8-4885-e3c9-54b50ea1eee5","executionInfo":{"status":"ok","timestamp":1576124158507,"user_tz":300,"elapsed":3032,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":669}},"source":["movie_data_sample_2['Genre'].value_counts().reset_index()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Genre</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Drama</td>\n","      <td>781</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Comedy</td>\n","      <td>499</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Documentary</td>\n","      <td>323</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Comedy|Drama</td>\n","      <td>312</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Drama|Romance</td>\n","      <td>275</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Comedy|Drama|Romance</td>\n","      <td>233</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Comedy|Romance</td>\n","      <td>194</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Horror</td>\n","      <td>145</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Crime|Drama</td>\n","      <td>107</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Drama|Thriller</td>\n","      <td>104</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Action|Crime|Drama</td>\n","      <td>102</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Horror|Thriller</td>\n","      <td>92</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Crime|Drama|Thriller</td>\n","      <td>81</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Thriller</td>\n","      <td>65</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Crime|Drama|Mystery</td>\n","      <td>64</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Horror|Mystery|Thriller</td>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Western</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Action|Crime|Thriller</td>\n","      <td>59</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Drama|War</td>\n","      <td>58</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Biography|Drama</td>\n","      <td>55</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                      index  Genre\n","0                     Drama    781\n","1                    Comedy    499\n","2               Documentary    323\n","3              Comedy|Drama    312\n","4             Drama|Romance    275\n","5      Comedy|Drama|Romance    233\n","6            Comedy|Romance    194\n","7                    Horror    145\n","8               Crime|Drama    107\n","9            Drama|Thriller    104\n","10       Action|Crime|Drama    102\n","11          Horror|Thriller     92\n","12     Crime|Drama|Thriller     81\n","13                 Thriller     65\n","14      Crime|Drama|Mystery     64\n","15  Horror|Mystery|Thriller     61\n","16                  Western     60\n","17    Action|Crime|Thriller     59\n","18                Drama|War     58\n","19          Biography|Drama     55"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"8HsoGiJEZ04U","colab_type":"text"},"source":["## Split Movies with more than one Genre into one: "]},{"cell_type":"code","metadata":{"id":"zvEXv3PGZ2X8","colab_type":"code","colab":{}},"source":["label_dict = {\"word2id\": {}, \"id2word\": []}\n","idx = 0\n","genre_per_movie = movie_data_sample_2[\"Genre\"].apply(lambda x: str(x).split(\"|\")[:-1])\n","for l in [g for d in genre_per_movie for g in d]:\n","    if l in label_dict[\"id2word\"]:\n","        pass\n","    else:\n","        label_dict[\"id2word\"].append(l)\n","        label_dict[\"word2id\"][l] = idx\n","        idx += 1\n","n_classes = len(label_dict[\"id2word\"])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGjGpumOZ4Xj","colab_type":"code","colab":{}},"source":["def genre_count(df, label_dict):\n","    max_genre = 0\n","    for label in label_dict[\"id2word\"]:\n","        occurrences = len((df[df['Genre'].str.contains(label)]))\n","        print(label, occurrences)\n","        if occurrences > max_genre:\n","            max_genre = occurrences\n","    return max_genre"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6hpLi0KcZ6eB","colab_type":"code","outputId":"ea0fa680-30e6-4595-ae92-01ba66528c31","executionInfo":{"status":"ok","timestamp":1576124158516,"user_tz":300,"elapsed":3009,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["genres_split = genre_count(movie_data_sample_2, label_dict)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Comedy 1238\n","Crime 413\n","Drama 2172\n","Horror 298\n","Mystery 125\n","Action 161\n","Biography 55\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TgxNV7ywZ_R8","colab_type":"text"},"source":["### Since there is imbalance on the data set, we will take from original set the ones with less counts per Genre:"]},{"cell_type":"code","metadata":{"id":"oEfM2YLzZ8mx","colab_type":"code","outputId":"cdf6ca47-f932-492b-a1e6-ee48911213f1","executionInfo":{"status":"ok","timestamp":1576124158548,"user_tz":300,"elapsed":3014,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["# IMBALANCE: OVERSAMPLING SOLUTION\n","movie_data_copy = movie_data_remaining[~movie_data_remaining[\"Genre\"].str.contains(\"Comedy|Drama\")].copy()\n","    \n","for label in label_dict[\"id2word\"]:\n","    if label not in [\"Drama\", \"Comedy\"]:\n","        len_genre = len(movie_data_sample_2[movie_data_sample_2['Genre'].str.contains(label)])\n","        df_genre = movie_data_copy[movie_data_copy['Genre'].str.contains(label)]\n","        #df_genre['genres'] = [label+\"|\" for i in range (0, len(df_genre))]    \n","        if (genres_split - len_genre) > 0:\n","            if len_genre > 3000:\n","                param = 0\n","            elif len_genre > 2000:\n","                param = 0.3\n","            elif len_genre > 1000:\n","                param = 0.5\n","            else:\n","                param = 0.9\n","            df_class_over = df_genre.sample(int((genres_split-len_genre)*param)+1, replace=True)\n","            movie_data_sample_2 = pd.concat([movie_data_sample_2, df_class_over], axis=0)\n","\n","print('Random over-sampling:')\n","print(genre_count(movie_data_sample_2, label_dict))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Random over-sampling:\n","Comedy 1238\n","Crime 2607\n","Drama 2172\n","Horror 2627\n","Mystery 2059\n","Action 1802\n","Biography 1969\n","2627\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oLGEkmIraDmI","colab_type":"code","outputId":"3f869f34-d6ff-4ff0-f1c4-e58952018d98","executionInfo":{"status":"ok","timestamp":1576124158548,"user_tz":300,"elapsed":2984,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Data Availability: \", len(movie_data_sample_2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Data Availability:  10459\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gbDFTRJZ2Aq2","colab_type":"code","colab":{}},"source":["def get_final_movie_data(movie_data):\n","    # new data frame with split value columns \n","    movie_data = movie_data.copy()\n","    split_genres = movie_data[\"Genre\"].str.split(\"|\", n = 2, expand = True) \n","    \n","    # making separate first name column from new data frame \n","    movie_data[\"Genre_1\"]= split_genres[0] \n","    \n","    # making separate last name column from new data frame \n","    movie_data[\"Genre_2\"]= split_genres[1] \n","    \n","    movie_data_genre_1 = movie_data[[\"imdbId\",\"Genre_1\"]]\n","    \n","    movie_data_genre_1.drop_duplicates(inplace=True, keep='first')\n","    movie_data_genre_1.rename(columns={'Genre_1':'Genre'}, inplace=True)\n","    \n","    movie_data_genre_2 = movie_data[[\"imdbId\",\"Genre_2\"]]\n","    movie_data_genre_2.drop_duplicates(inplace=True, keep='first')\n","    movie_data_genre_2.rename(columns={'Genre_2':'Genre'}, inplace=True)\n","    \n","    \n","    final_movie_data = pd.concat([movie_data_genre_2, movie_data_genre_1])\n","    \n","    print(len(final_movie_data))\n","    final_movie_data = final_movie_data.loc[~final_movie_data['Genre'].isin([None])]\n","    print(len(final_movie_data))\n","    \n","    return final_movie_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"veTqojwc2BBL","colab_type":"code","outputId":"5b7b08de-3e95-49db-d71c-302831c39a62","executionInfo":{"status":"ok","timestamp":1576124158550,"user_tz":300,"elapsed":2941,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":309}},"source":["final_movie_data = get_final_movie_data(movie_data_sample_2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["13278\n","11017\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4238: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  return super().rename(**kwargs)\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"pRyHQU3H2BSz","colab_type":"code","outputId":"cd4d0c53-71e5-4625-9060-56237c0c86b3","executionInfo":{"status":"ok","timestamp":1576124158550,"user_tz":300,"elapsed":2905,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":793}},"source":["final_movie_data[\"Genre\"].value_counts().reset_index()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Genre</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Drama</td>\n","      <td>2070</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Horror</td>\n","      <td>1490</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Comedy</td>\n","      <td>1238</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Crime</td>\n","      <td>1116</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Action</td>\n","      <td>1012</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Documentary</td>\n","      <td>780</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Thriller</td>\n","      <td>692</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Mystery</td>\n","      <td>620</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Romance</td>\n","      <td>513</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Biography</td>\n","      <td>472</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Adventure</td>\n","      <td>310</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Sci-Fi</td>\n","      <td>192</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Fantasy</td>\n","      <td>146</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Animation</td>\n","      <td>99</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Western</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>War</td>\n","      <td>59</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Film-Noir</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Short</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>History</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Family</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Music</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Musical</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Sport</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Adult</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          index  Genre\n","0         Drama   2070\n","1        Horror   1490\n","2        Comedy   1238\n","3         Crime   1116\n","4        Action   1012\n","5   Documentary    780\n","6      Thriller    692\n","7       Mystery    620\n","8       Romance    513\n","9     Biography    472\n","10    Adventure    310\n","11       Sci-Fi    192\n","12      Fantasy    146\n","13    Animation     99\n","14      Western     72\n","15          War     59\n","16    Film-Noir     38\n","17        Short     37\n","18      History     18\n","19       Family     17\n","20        Music     14\n","21      Musical      6\n","22        Sport      5\n","23        Adult      1"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"vb4GV8AykP_6","colab_type":"code","outputId":"e0c27b0a-fe0f-434f-8af3-fd0464e753a7","executionInfo":{"status":"ok","timestamp":1576124158550,"user_tz":300,"elapsed":2855,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":235}},"source":["final_movie_data_Genre_List = final_movie_data[\"Genre\"].value_counts()[0:6].reset_index()\n","final_movie_data_Genre_List"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Genre</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Drama</td>\n","      <td>2070</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Horror</td>\n","      <td>1490</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Comedy</td>\n","      <td>1238</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Crime</td>\n","      <td>1116</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Action</td>\n","      <td>1012</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Documentary</td>\n","      <td>780</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         index  Genre\n","0        Drama   2070\n","1       Horror   1490\n","2       Comedy   1238\n","3        Crime   1116\n","4       Action   1012\n","5  Documentary    780"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"xm2ycGgwkRnr","colab_type":"code","outputId":"7c5e4755-d877-4a3a-d769-dedfe1ae0655","executionInfo":{"status":"ok","timestamp":1576124158551,"user_tz":300,"elapsed":2839,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["final_movie_data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>imdbId</th>\n","      <th>Genre</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10177</th>\n","      <td>45607</td>\n","      <td>Romance</td>\n","    </tr>\n","    <tr>\n","      <th>20390</th>\n","      <td>1130087</td>\n","      <td>Romance</td>\n","    </tr>\n","    <tr>\n","      <th>9222</th>\n","      <td>172543</td>\n","      <td>Romance</td>\n","    </tr>\n","    <tr>\n","      <th>33543</th>\n","      <td>4338434</td>\n","      <td>Drama</td>\n","    </tr>\n","    <tr>\n","      <th>19079</th>\n","      <td>882969</td>\n","      <td>Romance</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        imdbId    Genre\n","10177    45607  Romance\n","20390  1130087  Romance\n","9222    172543  Romance\n","33543  4338434    Drama\n","19079   882969  Romance"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"DTzy9g2DkXc8","colab_type":"code","colab":{}},"source":["final_movie_data = final_movie_data.loc[final_movie_data['Genre'].isin(final_movie_data_Genre_List['index'])]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GSyKnRHIkbm7","colab_type":"code","outputId":"c8dbac4d-99ee-40e4-b380-83a50aeeb2df","executionInfo":{"status":"ok","timestamp":1576124158552,"user_tz":300,"elapsed":2798,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(final_movie_data)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7706"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"r_3yJxH9tAiu","colab_type":"code","outputId":"4188e2b4-eef6-468d-d73a-cc10eeff4711","executionInfo":{"status":"ok","timestamp":1576124159001,"user_tz":300,"elapsed":3231,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":419}},"source":["final_movie_data"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>imdbId</th>\n","      <th>Genre</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>33543</th>\n","      <td>4338434</td>\n","      <td>Drama</td>\n","    </tr>\n","    <tr>\n","      <th>2236</th>\n","      <td>118636</td>\n","      <td>Drama</td>\n","    </tr>\n","    <tr>\n","      <th>6082</th>\n","      <td>100442</td>\n","      <td>Drama</td>\n","    </tr>\n","    <tr>\n","      <th>1094</th>\n","      <td>116581</td>\n","      <td>Drama</td>\n","    </tr>\n","    <tr>\n","      <th>2607</th>\n","      <td>130827</td>\n","      <td>Drama</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5387</th>\n","      <td>303353</td>\n","      <td>Documentary</td>\n","    </tr>\n","    <tr>\n","      <th>38721</th>\n","      <td>3593124</td>\n","      <td>Documentary</td>\n","    </tr>\n","    <tr>\n","      <th>39760</th>\n","      <td>3520318</td>\n","      <td>Documentary</td>\n","    </tr>\n","    <tr>\n","      <th>28503</th>\n","      <td>3181314</td>\n","      <td>Documentary</td>\n","    </tr>\n","    <tr>\n","      <th>9447</th>\n","      <td>342150</td>\n","      <td>Documentary</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7706 rows × 2 columns</p>\n","</div>"],"text/plain":["        imdbId        Genre\n","33543  4338434        Drama\n","2236    118636        Drama\n","6082    100442        Drama\n","1094    116581        Drama\n","2607    130827        Drama\n","...        ...          ...\n","5387    303353  Documentary\n","38721  3593124  Documentary\n","39760  3520318  Documentary\n","28503  3181314  Documentary\n","9447    342150  Documentary\n","\n","[7706 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"bQJ9VK862P9b","colab_type":"text"},"source":["## 1.2  Extract posters into desired path (Only run once): "]},{"cell_type":"markdown","metadata":{"id":"OsDbEqrZFeZw","colab_type":"text"},"source":["#### 1.2 Load the image filepaths and thir corresponding labels into lists:\n","##### We need to do some preprocessing for movies without a defined genre, droping this movies of the set. "]},{"cell_type":"code","metadata":{"id":"XMGZaEnl7ggZ","colab_type":"code","colab":{}},"source":["final_movie_data['imdbId'] = final_movie_data['imdbId'].astype(str)\n","final_movie_data['imdbId_jpg'] = final_movie_data['imdbId']+'.jpg'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PPdX8uFqFeaB","colab_type":"text"},"source":["# 2.0 Process the labels:"]},{"cell_type":"markdown","metadata":{"id":"ckoTJPWFFeaC","colab_type":"text"},"source":["### Check that all files are images in the posters directory: "]},{"cell_type":"markdown","metadata":{"id":"9U5-o_WmFeaL","colab_type":"text"},"source":["### 2.1 Labels pre-proccesing:\n","\n","#### # Match final ids with labels:"]},{"cell_type":"markdown","metadata":{"id":"14s5DoOwkql7","colab_type":"text"},"source":["### Check that all files are images in the posters directory: "]},{"cell_type":"code","metadata":{"id":"XzR80Ff0kpWV","colab_type":"code","colab":{}},"source":["import imghdr\n","import os\n","def get_images_only(movie_filepaths):\n","    print(len(movie_filepaths))\n","    for image in movie_filepaths:\n","        if not (imghdr.what(image) == \"jpeg\") | (imghdr.what(image) == \"png\") :\n","            movie_filepaths.remove(image)\n","    print(len(movie_filepaths))\n","    \n","    return movie_filepaths"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"71i7jIgpvHzu","colab_type":"code","colab":{}},"source":["import glob\n","def get_available_posters(movies_dir, movie_sample):\n","  image_dir = glob.glob(movies_dir + \"*.jpg\")\n","  df_available_posters = pd.DataFrame(image_dir, columns=['posters'])\n","  print(df_available_posters.head())\n","  split_posters = df_available_posters[\"posters\"].str.split(\"/\", n = 6, expand = True) \n","    \n","  # making separate last name column from new data frame \n","  df_available_posters[\"split_1\"]= split_posters[5] \n","    \n","  final_split = df_available_posters[\"split_1\"].str.split(\".\", n = 2, expand = True) \n","  df_available_posters[\"available_id\"]= final_split[0]     \n","  print(df_available_posters.head())\n","    \n","  movie_sample = movie_sample.copy()\n","    \n","  print(len(movie_sample))\n","  movie_sample = movie_sample.loc[movie_sample['imdbId'].isin(df_available_posters[\"available_id\"])]\n","  print(len(movie_sample))\n","    \n","  return movie_sample"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSbCieZMvTQT","colab_type":"code","outputId":"de521e51-f243-4492-9696-69586ad75c38","executionInfo":{"status":"ok","timestamp":1576124159372,"user_tz":300,"elapsed":3499,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["final_movie_dataset = get_available_posters(movies_dir, final_movie_data)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["                                             posters\n","0  gdrive/My Drive/ECE 542 F3/data/posters/248617...\n","1  gdrive/My Drive/ECE 542 F3/data/posters/354364...\n","2  gdrive/My Drive/ECE 542 F3/data/posters/75984.jpg\n","3  gdrive/My Drive/ECE 542 F3/data/posters/901206...\n","4  gdrive/My Drive/ECE 542 F3/data/posters/142233...\n","                                             posters     split_1 available_id\n","0  gdrive/My Drive/ECE 542 F3/data/posters/248617...  248617.jpg       248617\n","1  gdrive/My Drive/ECE 542 F3/data/posters/354364...  354364.jpg       354364\n","2  gdrive/My Drive/ECE 542 F3/data/posters/75984.jpg   75984.jpg        75984\n","3  gdrive/My Drive/ECE 542 F3/data/posters/901206...  901206.jpg       901206\n","4  gdrive/My Drive/ECE 542 F3/data/posters/142233...  142233.jpg       142233\n","7706\n","7664\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lMe4hNDZx7Dw","colab_type":"code","colab":{}},"source":["final_filenames = [movies_dir + fname for fname in final_movie_dataset['imdbId_jpg'].tolist()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yqv26NtoyBgP","colab_type":"code","outputId":"5a0dc112-bae3-40ad-e031-408c91bc5d59","executionInfo":{"status":"ok","timestamp":1576124159374,"user_tz":300,"elapsed":3445,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["final_filenames[0:5]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['gdrive/My Drive/ECE 542 F3/data/posters/4338434.jpg',\n"," 'gdrive/My Drive/ECE 542 F3/data/posters/118636.jpg',\n"," 'gdrive/My Drive/ECE 542 F3/data/posters/100442.jpg',\n"," 'gdrive/My Drive/ECE 542 F3/data/posters/116581.jpg',\n"," 'gdrive/My Drive/ECE 542 F3/data/posters/130827.jpg']"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"wTrmcte-yCGW","colab_type":"code","outputId":"72917c80-f39c-46ca-f958-c0f21e46f6d6","executionInfo":{"status":"ok","timestamp":1576124159375,"user_tz":300,"elapsed":3383,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(final_filenames)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7664"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"code","metadata":{"id":"qWijMpIyktDg","colab_type":"code","colab":{}},"source":["#final_filenames = get_images_only(filenames)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_vh37T1ktVX","colab_type":"code","colab":{}},"source":["#final_filenames = get_images_only(final_filenames)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YiEXmeYZFeaL","colab_type":"code","colab":{}},"source":["#from sklearn.preprocessing import LabelBinarizer\n","#encoder = LabelBinarizer()\n","#labels_cat_1hot = encoder.fit_transform(labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sW4bzroWFeaT","colab_type":"code","colab":{}},"source":["final_labels = final_movie_dataset['Genre'].tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VNkmEuCbFeaV","colab_type":"text"},"source":["### 2.2 Hot Encoding of Labels: "]},{"cell_type":"code","metadata":{"id":"JhMCqKdPFeaW","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import LabelEncoder\n","le_genre = LabelEncoder()\n","genre_encoded = le_genre.fit_transform(final_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Q9YtQGSFeaZ","colab_type":"code","outputId":"8d2d4aef-f6eb-4692-b37c-51d4327ebbe2","executionInfo":{"status":"ok","timestamp":1576124159922,"user_tz":300,"elapsed":3831,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["set(genre_encoded)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0, 1, 2, 3, 4, 5}"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"M_4nxN6IFeac","colab_type":"code","outputId":"ba2e80dd-1511-4584-d2b4-9cd38fbb44fe","executionInfo":{"status":"ok","timestamp":1576124159922,"user_tz":300,"elapsed":3826,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Shape of labels: \", genre_encoded.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Shape of labels:  (7664,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f_UtNk_9Feaf","colab_type":"text"},"source":["# 3. Split the data into training, validation and testing: \n","* Since amount of data is moderate, we will use training 70%  and cross validation to select best hyperparameters \n","* Finally evaluate the performance in the testing set 30% of total data"]},{"cell_type":"code","metadata":{"id":"Dl2w4YnJFeag","colab_type":"code","colab":{}},"source":["def stratified_split(X, y, test_size=0.2, validate_size=0.2):\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=test_size)\n","\n","    # need to do calculate new split size. \n","    # let's assume we had 100 samples and we don't do this\n","    # then the split will be 20 + (20% of 80) + (80% of 80). \n","    # But we want 20 + 20 + 60\n","    new_validate_size = validate_size / (1 - test_size)\n","    \n","    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=new_validate_size)\n","    \n","    y_train_values = [[x, y_train.tolist().count(x)] for x in set(y_train.tolist())]\n","    y_val_values = [[x, y_val.tolist().count(x)] for x in set(y_val.tolist())]\n","    \n","    print(\"Distribution of classes on training set: \", y_train_values)\n","    print(\"\\nDistribution of classes on testing set: \", y_val_values)\n","\n","    return X_train, X_test, X_val, y_train.tolist(), y_test.tolist(), y_val.tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1b4LV-_vFeai","colab_type":"code","outputId":"23fecbab-bc6c-44b4-beb5-6385d2e17946","executionInfo":{"status":"ok","timestamp":1576124159924,"user_tz":300,"elapsed":3816,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["train_X, test_X, val_X, train_Y, test_Y, val_Y = stratified_split(final_filenames, genre_encoded)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Distribution of classes on training set:  [[0, 604], [1, 736], [2, 667], [3, 467], [4, 1233], [5, 891]]\n","\n","Distribution of classes on testing set:  [[0, 201], [1, 245], [2, 223], [3, 156], [4, 411], [5, 297]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XFs5un3yFeak","colab_type":"text"},"source":["--------------------------------------------------------------------\n","# 3.1 Exploring the Data:\n"]},{"cell_type":"code","metadata":{"id":"ortjoYMbFeal","colab_type":"code","outputId":"1e779ef4-58df-4edc-be44-1c5a9ecd1a0a","executionInfo":{"status":"ok","timestamp":1576124159925,"user_tz":300,"elapsed":3814,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"total images in training set: \", len(train_X))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total images in training set:  4598\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"38ybLYQ0Fean","colab_type":"code","outputId":"f7da1145-7201-4417-858e-65a081cfacd7","executionInfo":{"status":"ok","timestamp":1576124159925,"user_tz":300,"elapsed":3793,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"total images in validation set: \", len(val_X))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total images in validation set:  1533\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QMQkBNjLFear","colab_type":"code","outputId":"644384a4-2514-440d-e8a8-0a909add193a","executionInfo":{"status":"ok","timestamp":1576124159926,"user_tz":300,"elapsed":3765,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"total images in testing data: \", len(test_Y))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total images in testing data:  1533\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Rc7Yc9M7Feau","colab_type":"text"},"source":["## 3.1.1 Exploration of labels: "]},{"cell_type":"code","metadata":{"id":"vVyT2f1-Feav","colab_type":"code","colab":{}},"source":["unique_labels = set(final_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"5yC1zUZSFeax","colab_type":"code","outputId":"a7e64d33-7b46-4aff-aa94-ed9e3ae6f3f3","executionInfo":{"status":"ok","timestamp":1576124159927,"user_tz":300,"elapsed":3756,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(unique_labels)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'Crime', 'Action', 'Comedy', 'Drama', 'Horror', 'Documentary'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Mi0n0Q2EFea0","colab_type":"text"},"source":["# 4. Create tf.data.Dataset Objects:\n","\n","* Creates a `Dataset` whose elements are slices of the given tensors.\n","\n","* Creates a constant tensor.\n"]},{"cell_type":"code","metadata":{"id":"pwY9xCa7Fea1","colab_type":"code","colab":{}},"source":["train_data = tf.data.Dataset.from_tensor_slices((tf.constant(train_X), tf.constant(train_Y)))\n","val_data = tf.data.Dataset.from_tensor_slices((tf.constant(val_X), tf.constant(val_Y)))\n","test_data = tf.data.Dataset.from_tensor_slices((tf.constant(test_X), tf.constant(test_Y)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UBvB5qxBFea3","colab_type":"text"},"source":["## 4.1. Convert file path into image with Tensorflow function:"]},{"cell_type":"code","metadata":{"id":"nCJgR2KjFea4","colab_type":"code","colab":{}},"source":["def load_preprocess(filepath, label):\n","    \"\"\"\n","    1.- Read Image from file path.\n","    \n","    2.- Decode a JPEG-encoded image to a uint8 tensor, \n","    The attr `channels` indicates the desired number of color channels for the decoded image.\n","    \n","    3.- Convert `image` to `dtype`, scaling its values if needed.\n","    Images that are represented using floating point values are expected to have\n","    values in the range [0,1)\n","    \n","    4.- Resize `images` to `size` using the specified `method`.\n","    Resized images will be distorted if their original aspect ratio is not the same as `size`.\n","    \"\"\"\n","    # 1\n","    image = tf.io.read_file(filepath)\n","    # 2\n","    image = tf.image.decode_jpeg(image, channels = 3)\n","    # 3\n","    image_normalized = (tf.cast(image, tf.float32))\n","    #image = tf.image.convert_image_dtype(image_normalized, tf.float32)\n","    # 4\n","    image = tf.image.resize(image_normalized, (IMG_Width, IMG_Height))\n","    return image, label"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VyJ1og4TFea8","colab_type":"text"},"source":["## This transformation applies `map_func` to each element of this dataset, and returns a new dataset containing the transformed elements, in the same order as they appeared in the input.\n","\n","## # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n"]},{"cell_type":"code","metadata":{"id":"rRRh9BbvFea9","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 32\n","IMG_Width = 182\n","IMG_Height = 268 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKVwle2jFebB","colab_type":"code","outputId":"5cc78124-a9e7-426f-a2cf-66ca719f6e1b","executionInfo":{"status":"ok","timestamp":1576124159930,"user_tz":300,"elapsed":3673,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_data"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.int32)>"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"B9T53FVaFebD","colab_type":"code","colab":{}},"source":["training_set = (train_data.map(load_preprocess).shuffle(buffer_size=10000).batch(BATCH_SIZE))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SLDuQzJ2FebH","colab_type":"code","colab":{}},"source":["val_set = (val_data.map(load_preprocess).shuffle(buffer_size=10000).batch(BATCH_SIZE))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mu6-w5nIFebJ","colab_type":"code","colab":{}},"source":["test_set = (test_data.map(load_preprocess).shuffle(buffer_size=10000).batch(BATCH_SIZE))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"q2JU20Dg3WVu","colab":{}},"source":["#for image, label in training_set.take(1):\n","#    print(\"Image Shape: \", image.numpy().shape)\n","#    print(\"Label: \", label.numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c-cqcryoFebS","colab_type":"text"},"source":["---------------------------------------------------------------------------------------\n","# 5.0 Model Definition \n","* Build the tf.keras.Sequential model by stacking layers:"]},{"cell_type":"code","metadata":{"id":"cflZ9YFiFebU","colab_type":"code","colab":{}},"source":["Image_shape = (IMG_Width, IMG_Height, 3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oDcr_cwLFeba","colab_type":"code","outputId":"05731faa-4a8b-4910-96b3-3f1aed70aea1","executionInfo":{"status":"ok","timestamp":1576124160614,"user_tz":300,"elapsed":4319,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(Image_shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(182, 268, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PfJ2KKgoFebc","colab_type":"text"},"source":["* Layer 1: Flatten: transforms the format of the images from 28,28 into one dimensional array of 784 pixels. \n","\n","* Layer 2: Convolutional 2D layer, with filter size of (3,3) and 32 number of filters.\n","\n","* Layer 3: Max Pooling: after each convolution layer to reduce the spatial size (computational Complexity) it also helps with the overfitting problem.\n","\n","* Layer 4: Dense layer to interpret the features, in this case with 80 nodes.\n","\n","* Layer 5: DropOut: for overfitting. \n","\n","* Layer 5: Final Layer that consists of 10 nodes which are the total possibilities of predictions of the 10 class labels, each of the nodes contains a score.  "]},{"cell_type":"markdown","metadata":{"id":"wMVg7vISFebe","colab_type":"text"},"source":["## 5.1 Train Model & Model Validation (Hyperparameter tunning)\n","* Train model and run k-fold cross validation to select best hyperparameters (batch size, learning rate)."]},{"cell_type":"code","metadata":{"id":"IK9bQIMDFebf","colab_type":"code","colab":{}},"source":["def model_train_validation(model, train_data, train_label, n_folds=2, batch_size=32):\n","    # initialize list to store scores accuracy to plot:\n","    hist = []\n","    # start k-fold cross validation from training data, with k=1. (data will be splitted into half 50% - 50%)\n","    kfold_cross = KFold(n_folds, shuffle=True, random_state=2019)\n","    #save weights between validation splits\n","    model.save_weights('model.h5')\n","    # Perform the splits for training and validation:\n","    for train_index, val_index in kfold_cross.split(train_data):\n","        train_X, train_Y, val_X, val_Y = train_data[train_index], train_label[train_index], train_data[val_index], train_label[val_index]\n","        \n","        # train_test_split(filenames, labels, train_size=0.7, random_state=42)\n","        # Make sure we have the same weights for each validation. \n","        model.load_weights('model.h5')\n","        # Fit the model for each of the sets:\n","        history = model.fit(train_X, train_Y, epochs = 10, batch_size= batch_size,\n","                            validation_data = (val_X, val_Y), verbose=0)\n","        # Store history with accuracy and loss during training:\n","        hist.append(history)\n","    return hist"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tmqGNF8fFebi","colab_type":"code","colab":{}},"source":["def base_model(DropoutRate):\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Conv2D(32, (3,3), input_shape=Image_shape ,activation='relu'), \n","        tf.keras.layers.MaxPooling2D((2,2)),\n","        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","        tf.keras.layers.MaxPooling2D((2,2)),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(100, activation = 'relu'),\n","        tf.keras.layers.Dropout(DropoutRate),\n","        tf.keras.layers.Dense(5, activation='softmax')\n","    ])\n","    return model\n","\n","def createUniqueModel(ConvL1Width, ConvL2Width, DropoutRate, Image_shape, DenseWidth = 50):\n","    # Model Definition:\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Conv2D(ConvL1Width, (3,3), input_shape=Image_shape ,activation='relu'), \n","        tf.keras.layers.MaxPooling2D((2,2)),\n","        tf.keras.layers.Conv2D(ConvL2Width, (3,3), activation='relu'),\n","        tf.keras.layers.MaxPooling2D((2,2)),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(DenseWidth, activation = 'relu'),\n","        tf.keras.layers.Dropout(DropoutRate),\n","        tf.keras.layers.Dense(5, activation='softmax')\n","    ])\n","    return model\n","#Model with batch norm\n","def createUniqueModelBN(ConvL1Width, ConvL2Width, Image_shape, DenseWidth = 50):\n","    # Model Definition:\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Conv2D(ConvL1Width, (3,3), input_shape=Image_shape ,activation='relu'), \n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.MaxPooling2D((2,2)),\n","        tf.keras.layers.Conv2D(ConvL2Width, (3,3), activation='relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.MaxPooling2D((2,2)),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(DenseWidth, activation = 'relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dense(5, activation='softmax')\n","    ])\n","    return model      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vho4IzV_Febk","colab_type":"code","colab":{}},"source":["#uniform log learning rate\n","def random_lmbda(): \n","    lmbda = [0.0001, 0.001, 0.01]\n","    lmbda = lmbda[np.random.randint(0,3)]\n","    return lmbda\n","\n","#use integer than divide by 100 to create probability\n","def random_dropout(dmin, dmax): \n","    dropout = np.random.randint(dmin,dmax)\n","    dropout = float(dropout)*.01\n","    return dropout\n","\n","#batch size\n","def random_batch_size():\n","    batch_sizes = [16, 32, 64] #smaller batch sizes since small data set\n","    batch_size = batch_sizes[np.random.randint(0,3)]\n","    return batch_size\n","\n","#ConvL1Width or L2 Width \n","def random_width(wmin, wmax):\n","    width = np.random.randint(wmin,wmax)\n","    return width\n","\n","def random_search(training_data, Image_shape):\n","    train_set = (training_data.map(load_preprocess).shuffle(buffer_size=10000))\n","    #train_augmented = (train_data_augment.map(load_augment).shuffle(buffer_size=10000))\n","    #train_combined = train_set.concatenate(train_augmented)\n","    \n","    #seperate sets\n","    train_x = []\n","    train_y = []\n","    \n","    for image, label in train_set:\n","        train_x.append(image.numpy())\n","        train_y.append(label.numpy())\n","    \n","    train_x = np.asarray(train_x)\n","    train_y = np.asarray(train_y)\n","    \n","    #verify proper inputs for cross validation\n","    print(train_x.shape,train_y.shape)\n","    \n","    for i in range(0, 3):\n","        lmbda = random_lmbda()\n","        dropout = random_dropout(20,50)\n","        optimizer = tf.optimizers.Adam(lmbda)\n","        width1 = random_width(4,16)\n","        width2 = random_width(16,32)\n","        dwidth = random_width(80, 120)\n","        #model =  base_model(dropout)\n","        model =  createUniqueModel(width1, width2, dropout, Image_shape, dwidth)\n","        #model = createUniqueModelBN(width1, width2, Image_shape, dwidth)\n","        model.compile(optimizer = optimizer, \n","                      loss = 'sparse_categorical_crossentropy', \n","                      metrics = ['sparse_categorical_accuracy'] )\n","        hist = model_train_validation(model, train_x, train_y, 2, 32)\n","        #print(lmbda,dropout)\n","        print(lmbda, dropout, width1, width2, dwidth)\n","        #print(lmbda,dropout,width1,width2,dwidth)\n","        print(hist[0].history['val_sparse_categorical_accuracy'])\n","        print(hist[1].history['val_sparse_categorical_accuracy'])\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W8KEufJfFebn","colab_type":"text"},"source":["## 5.2 Run Random Search: "]},{"cell_type":"code","metadata":{"id":"ZeFYuZ_UFebp","colab_type":"code","outputId":"cdc74441-5a44-411f-d17c-52266aa68c03","executionInfo":{"status":"error","timestamp":1576125414395,"user_tz":300,"elapsed":28831,"user":{"displayName":"Alex McKinnon","photoUrl":"","userId":"14284345672170281013"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["base_model = random_search(train_data, Image_shape = Image_shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(4598, 182, 268, 3) (4598,)\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-94-c1a958d82334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-93-42a5c4a39732>\u001b[0m in \u001b[0;36mrandom_search\u001b[0;34m(training_data, Image_shape)\u001b[0m\n\u001b[1;32m     53\u001b[0m                       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                       metrics = ['sparse_categorical_accuracy'] )\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_train_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;31m#print(lmbda,dropout)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-91-2fbb78495d71>\u001b[0m in \u001b[0;36mmodel_train_validation\u001b[0;34m(model, train_data, train_label, n_folds, batch_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Fit the model for each of the sets:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         history = model.fit(train_X, train_Y, epochs = 10, batch_size= batch_size,\n\u001b[0;32m---> 17\u001b[0;31m                             validation_data = (val_X, val_Y), verbose=0)\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Store history with accuracy and loss during training:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m:  Received a label value of 5 which is outside the valid range of [0, 5).  Label values: 5 4 2 4 4 5 5 5 5 3 5 5 0 4 5 1 0 2 4 5 2 2 0 5 4 3 3 1 1 0 5 4\n\t [[node loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_10339]\n\nFunction call stack:\ndistributed_function\n"]}]},{"cell_type":"code","metadata":{"id":"I9gh2VEUlQv-","colab_type":"code","colab":{}},"source":["acc_loss_plots_1_it(base_model.history)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bLV3rHioFebs","colab_type":"text"},"source":["## 5.3 Define Final Model: "]},{"cell_type":"code","metadata":{"id":"gsa9qYSiFebt","colab_type":"code","colab":{}},"source":["num_train = len(train_filenames)\n","num_epoch = 15\n","steps_per_epoch = round(num_train)//BATCH_SIZE\n","print(BATCH_SIZE)\n","val_steps = 12"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"93fADzMUFebv","colab_type":"code","colab":{}},"source":["# Model Definition:\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(14, (3,3), input_shape=Image_shape ,activation='relu'), \n","    #tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.MaxPooling2D((2,2)),\n","    tf.keras.layers.Conv2D(19, (3,3), activation='relu'),\n","    #tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.MaxPooling2D((2,2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation = 'relu'),\n","    #tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dropout(0.32),\n","    tf.keras.layers.Dense(10, activation='softmax')\n","])\n","# Compile the model:\n","model.compile(optimizer=tf.keras.optimizers.Adam(lr= 0.004584439568618798), \n","             loss='sparse_categorical_crossentropy',\n","             metrics=['sparse_categorical_accuracy'])\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1uI_wQWPFebx","colab_type":"code","colab":{}},"source":["history = model.fit(training_set.repeat(), epochs = num_epoch, steps_per_epoch = steps_per_epoch, \n","                   validation_data=val_set.repeat(), validation_steps=val_steps)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9UoOP-znFebz","colab_type":"text"},"source":["### 4.2 Plot Accuracy and validation traning loss"]},{"cell_type":"code","metadata":{"id":"lKQ1VP0MFeb0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xQskPlsyFeb2","colab_type":"text"},"source":["### 4.3 Save Model\n","* Save model parameters to disk. Skip if loading a previously trained model."]},{"cell_type":"code","metadata":{"id":"TWocEMWoFeb2","colab_type":"code","colab":{}},"source":["#model.save_weights('Model_Leaderbord_1_CNN_lr_0.00458_BS_20.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-dJabokpFeb7","colab_type":"text"},"source":["-------------------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"GQ5YnzlQFeb8","colab_type":"text"},"source":["# Transfer Learning from MobileNetV2:"]},{"cell_type":"code","metadata":{"id":"W4wQklQSFeb8","colab_type":"code","colab":{}},"source":["# Pre-trained model with MobileNetV2\n","base_model = tf.keras.applications.MobileNetV2(\n","    input_shape=Image_shape,\n","    include_top=False,\n","    weights='imagenet'\n",")\n","# Freeze the pre-trained model weights\n","base_model.trainable = False\n","\n","# Trainable classification head\n","maxpool_layer = tf.keras.layers.GlobalMaxPooling2D()\n","prediction_layer = tf.keras.layers.Dense(5, activation='softmax')\n","\n","# Layer classification head with feature detector\n","model_MOBILE_NET = tf.keras.Sequential([\n","    base_model,\n","    maxpool_layer,\n","    prediction_layer\n","])\n","\n","# Compile the model\n","model_MOBILE_NET.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), \n","              loss='sparse_categorical_crossentropy',\n","              metrics=['sparse_categorical_accuracy']\n",")\n","print(\"--------------------MobileNetV2---------------------------------------------\")\n","model_MOBILE_NET.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VmXyi-eLFeb_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NF3MfLiDFecC","colab_type":"text"},"source":["### 4.3 Save Model \n","* Save model parameters to disk. Skip if loading a previously trained model."]},{"cell_type":"code","metadata":{"id":"OIjJ00_KFecD","colab_type":"code","colab":{}},"source":["#model.save_weights('Model_Leaderbord_1_CNN_lr_0.00458_BS_20.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OxjPBCGAFecI","colab_type":"text"},"source":["### 4.2 Plot accuracy and model loss during training for train and validation set:"]},{"cell_type":"code","metadata":{"id":"ERosDvWlFecI","colab_type":"code","colab":{}},"source":["def acc_loss_plots_many_iterations(hist):\n","    for i in range(len(hist.history)):\n","        plt.subplot(211)\n","        plt.plot(hist[i].history['categorical_accuracy'], color='green', label='Training')\n","        plt.plot(hist[i].history['val_categorical_accuracy'], color='blue', label='Validation')\n","        plt.title('model accuracy')\n","        plt.ylabel('accuracy')\n","        plt.xlabel('epoch')\n","        plt.legend(loc='upper right')\n","        \n","        plt.subplot(212)\n","        plt.plot(hist[i].history['loss'], color='green', label='Training')\n","        plt.plot(hist[i].history['val_loss'], color='blue', label='Validation')\n","        plt.title('model loss')\n","        plt.ylabel('loss')\n","        plt.xlabel('epoch')\n","        plt.legend(loc='upper right')\n","    \n","    plt.tight_layout()\n","    #plt.savefig(\"Model_3_CNN_lr_0.0005_BS_30.png\", dpi=1200)\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LQGvXr6MFecK","colab_type":"code","colab":{}},"source":["def acc_loss_plots_1_it(hist):\n","    plt.figure(figsize=(8, 8))\n","    plt.subplot(211)\n","    plt.plot(hist.history['sparse_categorical_accuracy'], color='green', label='Training')\n","    plt.plot(hist.history['val_sparse_categorical_accuracy'], color='blue', label='Validation')\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(loc='upper right')\n","    \n","    plt.subplot(212)\n","    plt.plot(hist.history['loss'], color='green', label='Training')\n","    plt.plot(hist.history['val_loss'], color='blue', label='Validation')\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(loc='upper right')\n","    plt.tight_layout()\n","    \n","    plt.tight_layout()\n","    #plt.savefig(\"Model_3_CNN_lr_0.0005_BS_30.png\", dpi=1200)\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DlQnQ_koFecO","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"kgnoSnyxFecR","colab_type":"code","colab":{}},"source":["model.load_weights('Model_Leaderbord_1_CNN_lr_0.00458_BS_20.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0DA6uUlFecT","colab_type":"code","colab":{}},"source":["#model.load_weights('Model_Leaderbord_1_CNN_lr_0.00458_BS_32.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FuAgPiBmFecV","colab_type":"code","colab":{}},"source":["val_set = (val_data.map(load_preprocess).shuffle(buffer_size=10000))\n","\n","#seperate sets\n","val_x = []\n","val_y = []\n","\n","for image, label in val_set:\n","    val_x.append(image.numpy())\n","    val_y.append(label.numpy())\n","    \n","val_x = np.asarray(val_x)\n","val_y = np.asarray(val_y)\n","    \n","#verify proper inputs for cross validation\n","print(val_x.shape,val_y.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hzcZsfJBFecW","colab_type":"code","colab":{}},"source":["# evaluate loaded model on test data\n","model.compile(loss = 'sparse_categorical_crossentropy', optimizer = tf.optimizers.Adam(lr = 0.004584439568618798), \n","                     metrics = ['sparse_categorical_accuracy'])\n","score = model.evaluate(val_x, val_y, verbose=0)\n","print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eEgmIltdFecY","colab_type":"text"},"source":["### 4.4 Display CNN Architecture"]},{"cell_type":"code","metadata":{"id":"5jPQ5nG8FecZ","colab_type":"code","colab":{}},"source":["#tf.keras.utils.plot_model(model, to_file='Model_3_CNN_lr_0.0005_BS_30_relu_architecture.png')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K-wfunCiFeca","colab_type":"text"},"source":["## 5.0 Model Testing (Assesment) \n","* Evaluate model on testing set: "]},{"cell_type":"code","metadata":{"id":"VN7NxViXFecb","colab_type":"code","colab":{}},"source":["#Setup testing set\n","import os\n","test_files = os.listdir('data/Project_C2_Testing/')\n","test_files = ['data/Project_C2_Testing/' + f  for f in test_files]\n","test_files_len = len(test_files)\n","#just use empty labels for now since only conducting predictions\n","test_labels = [0]*test_files_len\n","#validate proper files\n","print(test_files[0:5])\n","print(len(test_labels))\n","print(test_files_len)\n","test_data = tf.data.Dataset.from_tensor_slices((tf.constant(test_files), tf.constant(test_labels)))\n","test_set = (test_data.map(load_preprocess).batch(BATCH_SIZE))\n","prediction = model.predict(test_set)\n","print(prediction.shape)\n","\n","f = open('predictions.csv', 'w')\n","f2 = open('predictions_one_hot.csv', 'w')\n","\n","for img in prediction: \n","    highVal = 0\n","    label = 0 \n","    index = 0\n","    for predict in img:\n","        if(predict > highVal):\n","            highVal = predict\n","            label = index\n","        index = index + 1\n","        \n","    #print integer predictions\n","    f.write(str(label) + '\\n')\n","    \n","    #print one hot encoding predictions\n","    for i in range(0,5):\n","        if(i == 4):\n","            if(i == label):\n","                f2.write('1\\n')\n","            else:\n","                f2.write('0\\n')\n","        else:\n","            if(i == label):\n","                f2.write('1,')\n","            else:\n","                f2.write('0,')\n","        \n","f.close()\n","f2.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c77vm078Fecd","colab_type":"code","colab":{}},"source":["_, acc = model.evaluate(test_set)\n","print(\"Model accuracy on testing set: {percent:.3%}\".format(percent=acc))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6o0aQl4qFecg","colab_type":"code","colab":{}},"source":["predictions = model.predict(test_set)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"do8arP2YFech","colab_type":"code","colab":{}},"source":["predictions_reshape = np.array(predictions).reshape(180, 1, 5)"],"execution_count":0,"outputs":[]}]}